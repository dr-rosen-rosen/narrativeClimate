{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "################# For running pre-training\n",
    "\n",
    "from transformers import BertTokenizer, DataCollatorForLanguageModeling, BertForMaskedLM, TrainingArguments, Trainer, logging\n",
    "import torch\n",
    "# import tensorflow as tf\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import re\n",
    "\n",
    "logging.set_verbosity_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# Set up GPU backend\n",
    "# https://pytorch.org/docs/main/notes/mps.html\n",
    "# https://stackoverflow.com/questions/63423463/using-pytorch-cuda-on-macbook-pro\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "    # output expected:\n",
    "    # tensor([1.], device='mps:0')\n",
    "\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395651\n",
      "395595\n",
      "375678\n"
     ]
    }
   ],
   "source": [
    "# Read in events, clean and store as dataset\n",
    "# https://towardsdatascience.com/does-bert-need-clean-data-part-2-classification-d29adf9f745a\n",
    "def text_clean(x):\n",
    "\n",
    "    ### Light\n",
    "    x = x.lower() # lowercase everything\n",
    "    x = x.encode('ascii', 'ignore').decode()  # remove unicode characters\n",
    "    x = re.sub(r'https*\\S+', ' ', x) # remove links\n",
    "    x = re.sub(r'http*\\S+', ' ', x)\n",
    "    # cleaning up text\n",
    "    x = re.sub(r'\\'\\w+', '', x) \n",
    "    x = re.sub(r'\\w*\\d+\\w*', '', x)\n",
    "    x = re.sub(r'\\s{2,}', ' ', x)\n",
    "    x = re.sub(r'\\s[^\\w\\s]\\s', '', x)\n",
    "    \n",
    "    # ### Heavy\n",
    "    # x = ' '.join([word for word in x.split(' ') if word not in stopwords])\n",
    "    # x = re.sub(r'@\\S', '', x)\n",
    "    # x = re.sub(r'#\\S+', ' ', x)\n",
    "    # x = re.sub('[%s]' % re.escape(string.punctuation), ' ', x)\n",
    "    # # remove single letters and numbers surrounded by space\n",
    "    # x = re.sub(r'\\s[a-z]\\s|\\s[0-9]\\s', ' ', x)\n",
    "\n",
    "    return x\n",
    "df = pd.read_csv('eid_eventText.csv', usecols=['eid','event_text']).dropna(how='any',axis=0)\n",
    "print(len(df))\n",
    "df.drop_duplicates(subset=['event_text'],keep='first',inplace=True)\n",
    "print(len(df))\n",
    "df['event_text'] = df.event_text.apply(text_clean)\n",
    "df = df[df['event_text'].str.split().str.len().gt(20)] # drops events with fewer than 20 words  \n",
    "df.rename(columns={\"event_text\":\"text\"},inplace=True)\n",
    "print(len(df))\n",
    "\n",
    "dataset = Dataset.from_pandas(df).shuffle(seed=242)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4524"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAHqCAYAAADLbQ06AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1KklEQVR4nO3de3RU9b3//9fkMgMxTgJCEtBwkwpyF5Q4VbGWHAJNtai/VhGVUgTR4BGxgGkrXk7PieLCSy1iPVZiz68V5ZyiVhGMAYKUABINEMC0KhSqJFRCZgBhJpl8vn/Q7DIkKITAfJI8H2vtVWbv93zmvfeivth3lzHGCAAAWCkm2g0AAIATI6gBALAYQQ0AgMUIagAALEZQAwBgMYIaAACLEdQAAFiMoAYAwGIEdTMxxigQCIjnxwAAmhNB3UwOHDigpKQkHThwINqtAABaEYIaAACLEdQAAFiMoAYAwGIENQAAFiOoAQCwGEENAIDFCGoAACxGUAMAYDGCGgAAixHUAABYjKAGAMBiBDUAABYjqAEAsBhBDQCAxQhqAAAsRlADAGAxghoAAIsR1AAAWIygtowxRqFQSMaYaLcCALAAQW2Zmpoa3TR/pWpqaqLdCgDAAgS1hWJi46LdAgDAEgQ1AAAWI6gBALAYQQ0AgMUIagAALEZQAwBgMYIaAACLEdQAAFiMoAYAwGJRDeoFCxZo0KBB8nq98nq98vl8euedd5zlR44cUU5Ojs477zwlJibqxhtvVGVlZcQYu3btUnZ2thISEpSSkqKZM2eqtrY2ombVqlUaOnSoPB6Pevfurfz8/Aa9zJ8/Xz169FC7du2UkZGhDRs2nJF1BgDgVEQ1qC+44AI99thjKikp0caNG/Xd735XP/jBD7R161ZJ0n333ac//elPWrx4sYqKivTFF1/ohhtucL4fDoeVnZ2tUCiktWvX6uWXX1Z+fr7mzJnj1OzYsUPZ2dm65pprVFpaqunTp+uOO+7Q8uXLnZpXX31VM2bM0EMPPaQPP/xQgwcPVlZWlvbu3Xv2NgYAAI0xlunQoYN58cUXTXV1tYmPjzeLFy92lm3fvt1IMsXFxcYYY5YuXWpiYmJMRUWFU7NgwQLj9XpNMBg0xhgza9Ys079//4jfuOmmm0xWVpbzefjw4SYnJ8f5HA6HTdeuXU1eXt5J9+33+40k4/f7T22FjxMMBs0Nz7zn9A8AaNusOUcdDoe1aNEiHTp0SD6fTyUlJaqpqVFmZqZT07dvX3Xr1k3FxcWSpOLiYg0cOFCpqalOTVZWlgKBgLNXXlxcHDFGfU39GKFQSCUlJRE1MTExyszMdGoAAIiWqL/9YcuWLfL5fDpy5IgSExO1ZMkS9evXT6WlpXK73UpOTo6oT01NVUVFhSSpoqIiIqTrl9cv+7qaQCCgw4cPa//+/QqHw43WfPzxxyfsOxgMKhgMOp8DgcCprTgAACch6nvUffr0UWlpqdavX6+77rpLEyZM0LZt26Ld1jfKy8tTUlKSM6Wnp0e7JQBAKxT1oHa73erdu7eGDRumvLw8DR48WM8884zS0tIUCoVUXV0dUV9ZWam0tDRJUlpaWoOrwOs/f1ON1+tV+/bt1alTJ8XGxjZaUz9GY3Jzc+X3+51p9+7dTVp/AAC+TtSD+nh1dXUKBoMaNmyY4uPjVVhY6CwrLy/Xrl275PP5JEk+n09btmyJuDq7oKBAXq9X/fr1c2qOHaO+pn4Mt9utYcOGRdTU1dWpsLDQqWmMx+NxbiurnwAAaHbRvJLtgQceMEVFRWbHjh1m8+bN5oEHHjAul8u8++67xhhjpk6darp162ZWrFhhNm7caHw+n/H5fM73a2trzYABA8yoUaNMaWmpWbZsmencubPJzc11aj777DOTkJBgZs6cabZv327mz59vYmNjzbJly5yaRYsWGY/HY/Lz8822bdvMlClTTHJycsTV5N+Eq74BAGdCVIP6Jz/5ienevbtxu92mc+fOZuTIkU5IG2PM4cOHzd133206dOhgEhISzPXXX2/27NkTMcbOnTvNmDFjTPv27U2nTp3M/fffb2pqaiJqVq5caYYMGWLcbrfp1auXWbhwYYNenn32WdOtWzfjdrvN8OHDzbp1605pXQhqAMCZ4DLGmGjv1bcGgUBASUlJ8vv9p3UYPBQKadzz7+uVqVfJ7XY3Y4cAgJbIunPUAADgXwhqAAAsRlADAGAxghoAAIsR1AAAWIygBgDAYgQ1AAAWI6gBALAYQQ0AgMUIagAALEZQAwBgMYIaAACLEdQAAFiMoAYAwGIENQAAFiOoAQCwGEENAIDFCGoAACxGUAMAYDGCGgAAixHUAABYjKAGAMBiBDUAABYjqAEAsBhBDQCAxQhqAAAsRlADAGAxghoAAIsR1AAAWIygBgDAYgQ1AAAWI6gBALAYQQ0AgMUIagvV1dYoFApFuw0AgAUIagAALEZQAwBgMYIaAACLEdQAAFiMoAYAwGIENQAAFiOoAQCwGEENAIDFCGoAACxGUAMAYDGCGgAAixHUAABYjKAGAMBiBDUAABYjqAEAsBhBDQCAxQhqAAAsRlADAGAxghoAAIsR1AAAWCyqQZ2Xl6fLLrtM5557rlJSUjR27FiVl5dH1HznO9+Ry+WKmKZOnRpRs2vXLmVnZyshIUEpKSmaOXOmamtrI2pWrVqloUOHyuPxqHfv3srPz2/Qz/z589WjRw+1a9dOGRkZ2rBhQ7OvMwAApyKqQV1UVKScnBytW7dOBQUFqqmp0ahRo3To0KGIusmTJ2vPnj3ONHfuXGdZOBxWdna2QqGQ1q5dq5dffln5+fmaM2eOU7Njxw5lZ2frmmuuUWlpqaZPn6477rhDy5cvd2peffVVzZgxQw899JA+/PBDDR48WFlZWdq7d++Z3xAAAJyIscjevXuNJFNUVOTMu/rqq8299957wu8sXbrUxMTEmIqKCmfeggULjNfrNcFg0BhjzKxZs0z//v0jvnfTTTeZrKws5/Pw4cNNTk6O8zkcDpuuXbuavLy8k+rd7/cbScbv959U/YkEg0Ezdt475sCBA6c1DgCgdbDqHLXf75ckdezYMWL+73//e3Xq1EkDBgxQbm6uvvrqK2dZcXGxBg4cqNTUVGdeVlaWAoGAtm7d6tRkZmZGjJmVlaXi4mJJUigUUklJSURNTEyMMjMznRoAAKIhLtoN1Kurq9P06dN1xRVXaMCAAc78W265Rd27d1fXrl21efNmzZ49W+Xl5frjH/8oSaqoqIgIaUnO54qKiq+tCQQCOnz4sPbv369wONxozccff9xov8FgUMFg0PkcCASauOYAAJyYNUGdk5OjsrIyrVmzJmL+lClTnD8PHDhQXbp00ciRI/Xpp5/qwgsvPNttOvLy8vTII49E7fcBAG2DFYe+p02bprfeeksrV67UBRdc8LW1GRkZkqRPPvlEkpSWlqbKysqImvrPaWlpX1vj9XrVvn17derUSbGxsY3W1I9xvNzcXPn9fmfavXv3Sa4tAAAnL6pBbYzRtGnTtGTJEq1YsUI9e/b8xu+UlpZKkrp06SJJ8vl82rJlS8TV2QUFBfJ6verXr59TU1hYGDFOQUGBfD6fJMntdmvYsGERNXV1dSosLHRqjufxeOT1eiMmAACaXTSvZLvrrrtMUlKSWbVqldmzZ48zffXVV8YYYz755BPz6KOPmo0bN5odO3aYN954w/Tq1cuMGDHCGaO2ttYMGDDAjBo1ypSWlpply5aZzp07m9zcXKfms88+MwkJCWbmzJlm+/btZv78+SY2NtYsW7bMqVm0aJHxeDwmPz/fbNu2zUyZMsUkJydHXE3+dbjqGwBwJkQ1qCU1Oi1cuNAYY8yuXbvMiBEjTMeOHY3H4zG9e/c2M2fObBCGO3fuNGPGjDHt27c3nTp1Mvfff7+pqamJqFm5cqUZMmSIcbvdplevXs5vHOvZZ5813bp1M2632wwfPtysW7fupNeFoAYAnAkuY4yJ3v586xEIBJSUlCS/339ah8FDoZBu+vUK/c+UK5WYmNiMHQIAWiIrLiYDAACNI6gBALAYQQ0AgMUIagAALEZQAwBgMYIaAACLEdQAAFiMoAYAwGIENQAAFiOoAQCwGEENAIDFCGoAACxGUAMAYDGCGgAAixHUAABYjKAGAMBiBDUAABYjqAEAsBhBDQCAxQhqAAAsRlADAGAxghoAAIsR1AAAWIygBgDAYgQ1AAAWI6gBALAYQQ0AgMUIagAALEZQAwBgMYIaAACLEdQAAFiMoAYAwGIENQAAFiOoAQCwGEENAIDFCGoAACxGUAMAYDGCGgAAixHUAABYjKAGAMBiBDUAABYjqAEAsBhBDQCAxQhqAAAsRlADAGAxghoAAIsR1AAAWIygBgDAYgQ1AAAWI6gBALAYQQ0AgMUIagAALEZQAwBgMYIaAACLEdQAAFgsqkGdl5enyy67TOeee65SUlI0duxYlZeXR9QcOXJEOTk5Ou+885SYmKgbb7xRlZWVETW7du1Sdna2EhISlJKSopkzZ6q2tjaiZtWqVRo6dKg8Ho969+6t/Pz8Bv3Mnz9fPXr0ULt27ZSRkaENGzY0+zoDAHAqohrURUVFysnJ0bp161RQUKCamhqNGjVKhw4dcmruu+8+/elPf9LixYtVVFSkL774QjfccIOzPBwOKzs7W6FQSGvXrtXLL7+s/Px8zZkzx6nZsWOHsrOzdc0116i0tFTTp0/XHXfcoeXLlzs1r776qmbMmKGHHnpIH374oQYPHqysrCzt3bv37GwMAAAaYyyyd+9eI8kUFRUZY4yprq428fHxZvHixU7N9u3bjSRTXFxsjDFm6dKlJiYmxlRUVDg1CxYsMF6v1wSDQWOMMbNmzTL9+/eP+K2bbrrJZGVlOZ+HDx9ucnJynM/hcNh07drV5OXlnVTvfr/fSDJ+v/8U1zpSMBg0Y+e9Yw4cOHBa4wAAWgerzlH7/X5JUseOHSVJJSUlqqmpUWZmplPTt29fdevWTcXFxZKk4uJiDRw4UKmpqU5NVlaWAoGAtm7d6tQcO0Z9Tf0YoVBIJSUlETUxMTHKzMx0ao4XDAYVCAQiJgAAmps1QV1XV6fp06friiuu0IABAyRJFRUVcrvdSk5OjqhNTU1VRUWFU3NsSNcvr1/2dTWBQECHDx/Wl19+qXA43GhN/RjHy8vLU1JSkjOlp6c3bcUBAPga1gR1Tk6OysrKtGjRomi3clJyc3Pl9/udaffu3dFuCQDQCsVFuwFJmjZtmt566y2tXr1aF1xwgTM/LS1NoVBI1dXVEXvVlZWVSktLc2qOvzq7/qrwY2uOv1K8srJSXq9X7du3V2xsrGJjYxutqR/jeB6PRx6Pp2krDADASYrqHrUxRtOmTdOSJUu0YsUK9ezZM2L5sGHDFB8fr8LCQmdeeXm5du3aJZ/PJ0ny+XzasmVLxNXZBQUF8nq96tevn1Nz7Bj1NfVjuN1uDRs2LKKmrq5OhYWFTg0AAFERzSvZ7rrrLpOUlGRWrVpl9uzZ40xfffWVUzN16lTTrVs3s2LFCrNx40bj8/mMz+dzltfW1poBAwaYUaNGmdLSUrNs2TLTuXNnk5ub69R89tlnJiEhwcycOdNs377dzJ8/38TGxpply5Y5NYsWLTIej8fk5+ebbdu2mSlTppjk5OSIq8m/Dld9AwDOhKgGtaRGp4ULFzo1hw8fNnfffbfp0KGDSUhIMNdff73Zs2dPxDg7d+40Y8aMMe3btzedOnUy999/v6mpqYmoWblypRkyZIhxu92mV69eEb9R79lnnzXdunUzbrfbDB8+3Kxbt+6k14WgBgCcCS5jjIne/nzrEQgElJSUJL/fL6/X2+RxQqGQbvr1Cv3PlCuVmJjYjB0CAFoia676BgAADRHUAABYjKAGAMBiBDUAABYjqAEAsBhBDQCAxQhqAAAsRlADAGAxghoAAIsR1AAAWIygBgDAYgQ1AAAWI6gBALAYQQ0AgMUIagAALEZQW8gYo1AoJF4VDgAgqC1kwrWa+NI61dTURLsVAECUEdSWiomNi3YLAAALENQAAFiMoLZUXW2NQqFQtNsAAEQZQQ0AgMUIagAALEZQAwBgsSYFda9evbRv374G86urq9WrV6/TbgoAABzVpKDeuXOnwuFwg/nBYFCff/75aTcFAACOOqWbdd98803nz8uXL1dSUpLzORwOq7CwUD169Gi25gAAaOtOKajHjh0rSXK5XJowYULEsvj4ePXo0UPz5s1rtuYAAGjrTimo6+rqJEk9e/bUBx98oE6dOp2RpgAAwFFNek7ljh07mrsPAADQiCY/ULqwsFCFhYXau3evs6dd76WXXjrtxgAAQBOD+pFHHtGjjz6qSy+9VF26dJHL5WruvgAAgJoY1M8//7zy8/N12223NXc/AADgGE26jzoUCunb3/52c/cCAACO06SgvuOOO/SHP/yhuXsBAADHadKh7yNHjuiFF17Qe++9p0GDBik+Pj5i+ZNPPtkszQEA0NY1Kag3b96sIUOGSJLKysoilnFhGQAAzadJQb1y5crm7gMAADSC11wCAGCxJu1RX3PNNV97iHvFihVNbggAAPxLk4K6/vx0vZqaGpWWlqqsrKzByzoAAEDTNSmon3rqqUbnP/zwwzp48OBpNQQAAP6lWc9R33rrrTznGwCAZtSsQV1cXKx27do155AAALRpTTr0fcMNN0R8NsZoz5492rhxox588MFmaQwAADQxqJOSkiI+x8TEqE+fPnr00Uc1atSoZmkMAAA0MagXLlzY3H0AAIBGNCmo65WUlGj79u2SpP79++uSSy5plqYAAMBRTQrqvXv36uabb9aqVauUnJwsSaqurtY111yjRYsWqXPnzs3ZIwAAbVaTrvq+5557dODAAW3dulVVVVWqqqpSWVmZAoGA/v3f/725ewQAoM1q0h71smXL9N577+niiy925vXr10/z58/nYjIAAJpRk/ao6+rqGryDWpLi4+NVV1d32k0BAICjmhTU3/3ud3Xvvffqiy++cOZ9/vnnuu+++zRy5Mhmaw4AgLauSUH961//WoFAQD169NCFF16oCy+8UD179lQgENCzzz7b3D0CANBmNekcdXp6uj788EO99957+vjjjyVJF198sTIzM5u1OQAA2rpT2qNesWKF+vXrp0AgIJfLpX/7t3/TPffco3vuuUeXXXaZ+vfvr/fff/+kx1u9erWuvfZade3aVS6XS6+//nrE8h//+MdyuVwR0+jRoyNqqqqqNH78eHm9XiUnJ2vSpEkN3uC1efNmXXXVVWrXrp3S09M1d+7cBr0sXrxYffv2Vbt27TRw4EAtXbr05DcMAABnyCkF9dNPP63JkyfL6/U2WJaUlKQ777xTTz755EmPd+jQIQ0ePFjz588/Yc3o0aO1Z88eZ3rllVcilo8fP15bt25VQUGB3nrrLa1evVpTpkxxlgcCAY0aNUrdu3dXSUmJnnjiCT388MN64YUXnJq1a9dq3LhxmjRpkj766CONHTtWY8eOVVlZ2UmvCwAAZ4Q5Bd26dTPbtm074fLt27eb9PT0UxnSIcksWbIkYt6ECRPMD37wgxN+Z9u2bUaS+eCDD5x577zzjnG5XObzzz83xhjz3HPPmQ4dOphgMOjUzJ492/Tp08f5/KMf/chkZ2dHjJ2RkWHuvPPOk+7f7/cbScbv95/0dxoTDAbNdY+/aa6b+5Y5cODAaY0FAGj5TmmPurKystHbsurFxcXpH//4x+n9y+E4q1atUkpKivr06aO77rpL+/btc5YVFxcrOTlZl156qTMvMzNTMTExWr9+vVMzYsQIud1upyYrK0vl5eXav3+/U3P8+fWsrCwVFxc367oAAHCqTimozz///K89HLx582Z16dLltJuqN3r0aP3ud79TYWGhHn/8cRUVFWnMmDEKh8OSpIqKCqWkpER8Jy4uTh07dlRFRYVTk5qaGlFT//mbauqXNyYYDCoQCERMAAA0t1O66vt73/ueHnzwQY0ePVrt2rWLWHb48GE99NBD+v73v99szd18883OnwcOHKhBgwbpwgsv1KpVq6J+v3ZeXp4eeeSRqPYAAGj9TmmP+he/+IWqqqp00UUXae7cuXrjjTf0xhtv6PHHH1efPn1UVVWln//852eqV/Xq1UudOnXSJ598IklKS0vT3r17I2pqa2tVVVWltLQ0p6aysjKipv7zN9XUL29Mbm6u/H6/M+3evfv0Vg4AgEacUlCnpqZq7dq1GjBggHJzc3X99dfr+uuv189+9jMNGDBAa9asaXAIuTn9/e9/1759+5zD6z6fT9XV1SopKXFqVqxYobq6OmVkZDg1q1evVk1NjVNTUFCgPn36qEOHDk5NYWFhxG8VFBTI5/OdsBePxyOv1xsxAQDQ3E75gSfdu3fX0qVLtX//fn3yyScyxuhb3/qWE3qn4uDBg87esSTt2LFDpaWl6tixozp27KhHHnlEN954o9LS0vTpp59q1qxZ6t27t7KysiQdfcjK6NGjNXnyZD3//POqqanRtGnTdPPNN6tr166SpFtuuUWPPPKIJk2apNmzZ6usrEzPPPOMnnrqKed37733Xl199dWaN2+esrOztWjRIm3cuDHiFi4AAKIimpecr1y50khqME2YMMF89dVXZtSoUaZz584mPj7edO/e3UyePNlUVFREjLFv3z4zbtw4k5iYaLxer5k4cWKD25o2bdpkrrzySuPxeMz5559vHnvssQa9vPbaa+aiiy4ybrfb9O/f37z99tuntC7cngUAOBNcxhgTzX8otBaBQEBJSUny+/2ndRg8FArph08vl1wx+v1dVysxMbEZuwQAtDRNeikHAAA4OwhqAAAsRlADAGAxghoAAIsR1AAAWIygBgDAYgQ1AAAWI6gBALAYQQ0AgMUIagAALEZQAwBgMYIaAACLEdQAAFiMoAYAwGIENQAAFiOoAQCwGEFtqbraGoVCoWi3AQCIMoIaAACLEdQAAFiMoAYAwGIENQAAFiOoAQCwGEENAIDFCGoAACxGUAMAYDGCGgAAixHUAABYjKAGAMBiBDUAABYjqAEAsBhBDQCAxQhqAAAsRlADAGAxghoAAIsR1AAAWIygBgDAYgQ1AAAWI6gBALAYQQ0AgMUIagAALEZQAwBgMYIaAACLEdQAAFiMoAYAwGIENQAAFiOoAQCwGEENAIDFCGoAACxGUAMAYDGCGgAAixHUAABYjKAGAMBiBDUAABYjqAEAsFhUg3r16tW69tpr1bVrV7lcLr3++usRy40xmjNnjrp06aL27dsrMzNTf/3rXyNqqqqqNH78eHm9XiUnJ2vSpEk6ePBgRM3mzZt11VVXqV27dkpPT9fcuXMb9LJ48WL17dtX7dq108CBA7V06dJmX18AAE5VVIP60KFDGjx4sObPn9/o8rlz5+pXv/qVnn/+ea1fv17nnHOOsrKydOTIEadm/Pjx2rp1qwoKCvTWW29p9erVmjJlirM8EAho1KhR6t69u0pKSvTEE0/o4Ycf1gsvvODUrF27VuPGjdOkSZP00UcfaezYsRo7dqzKysrO3MoDAHAyjCUkmSVLljif6+rqTFpamnniiSecedXV1cbj8ZhXXnnFGGPMtm3bjCTzwQcfODXvvPOOcblc5vPPPzfGGPPcc8+ZDh06mGAw6NTMnj3b9OnTx/n8ox/9yGRnZ0f0k5GRYe68886T7t/v9xtJxu/3n/R3GhMMBs11j79pvv9fS8y+fftOaywAQMtn7TnqHTt2qKKiQpmZmc68pKQkZWRkqLi4WJJUXFys5ORkXXrppU5NZmamYmJitH79eqdmxIgRcrvdTk1WVpbKy8u1f/9+p+bY36mvqf8dAACiJS7aDZxIRUWFJCk1NTVifmpqqrOsoqJCKSkpEcvj4uLUsWPHiJqePXs2GKN+WYcOHVRRUfG1v9OYYDCoYDDofA4EAqeyegAAnBRr96htl5eXp6SkJGdKT0+PdksAgFbI2qBOS0uTJFVWVkbMr6ysdJalpaVp7969Ectra2tVVVUVUdPYGMf+xolq6pc3Jjc3V36/35l27959qqsIAMA3sjaoe/bsqbS0NBUWFjrzAoGA1q9fL5/PJ0ny+Xyqrq5WSUmJU7NixQrV1dUpIyPDqVm9erVqamqcmoKCAvXp00cdOnRwao79nfqa+t9pjMfjkdfrjZgAAGhuUQ3qgwcPqrS0VKWlpZKOXkBWWlqqXbt2yeVyafr06frlL3+pN998U1u2bNHtt9+url27auzYsZKkiy++WKNHj9bkyZO1YcMG/fnPf9a0adN08803q2vXrpKkW265RW63W5MmTdLWrVv16quv6plnntGMGTOcPu69914tW7ZM8+bN08cff6yHH35YGzdu1LRp0872JokQCoUUCoWi2gMAIMqiecn5ypUrjaQG04QJE4wxR2/RevDBB01qaqrxeDxm5MiRpry8PGKMffv2mXHjxpnExETj9XrNxIkTzYEDByJqNm3aZK688krj8XjM+eefbx577LEGvbz22mvmoosuMm632/Tv39+8/fbbp7QuZ+L2rD179kTcVgYAaHtcxhgTzX8otBaBQEBJSUny+/2ndRg8FArph08vV7i2Vs/dOkypqanyeDzN2CkAoCWx9hx1W2fCtbr7//8w4tw6AKDtIagtFhNn7W3uAICzhKAGAMBiBDUAABYjqAEAsBhBDQCAxQhqAAAsRlADAGAxghoAAIsR1AAAWIygBgDAYgS1xYwxCoVC4nHsANB2EdQWM+FaTXxpHc/7BoA2jKC2XEwsz/sGgLaMoAYAwGIENQAAFiOoAQCwGEENAIDFCGoAACxGUAMAYDGCGgAAixHUAABYjKAGAMBiBDUAABYjqAEAsBhBDQCAxQhqAAAsRlADAGAxghoAAIsR1JYzxigUCskYE+1WAABRQFBbzoRrdetv1qimpibarQAAooCgbgFiYuOi3QIAIEoIagAALEZQAwBgMYK6BairrVEoFIp2GwCAKCCoAQCwGEENAIDFCGoAACxGUAMAYDGC2nJ1tTUypi7abQAAooSgBgDAYgQ1AAAWI6gBALAYQd1ChEIhHnoCAG0QQQ0AgMUIagAALEZQAwBgMYK6hTDGKBQKyRgT7VYAAGcRQd1C1NTU6NbfrFFNTU20WwEAnEUEdQsSExsX7RYAAGcZQd2C8F5qAGh7COoWoP78NACg7SGoWwATrtVdv9vAyzkAoA0iqFsIzk8DQNtEUAMAYDGrg/rhhx+Wy+WKmPr27essP3LkiHJycnTeeecpMTFRN954oyorKyPG2LVrl7Kzs5WQkKCUlBTNnDlTtbW1ETWrVq3S0KFD5fF41Lt3b+Xn55+N1QMA4BtZHdSS1L9/f+3Zs8eZ1qxZ4yy777779Kc//UmLFy9WUVGRvvjiC91www3O8nA4rOzsbIVCIa1du1Yvv/yy8vPzNWfOHKdmx44dys7O1jXXXKPS0lJNnz5dd9xxh5YvX35W1xMAgMZYf+IzLi5OaWlpDeb7/X799re/1R/+8Ad997vflSQtXLhQF198sdatW6fLL79c7777rrZt26b33ntPqampGjJkiP7jP/5Ds2fP1sMPPyy3263nn39ePXv21Lx58yRJF198sdasWaOnnnpKWVlZZ3Vdv8mxTydzuVzRbgcAcBZYv0f917/+VV27dlWvXr00fvx47dq1S5JUUlKimpoaZWZmOrV9+/ZVt27dVFxcLEkqLi7WwIEDlZqa6tRkZWUpEAho69atTs2xY9TX1I9xIsFgUIFAIGI600y4Vj/+bbEOHTrEo0QBoI2wOqgzMjKUn5+vZcuWacGCBdqxY4euuuoqHThwQBUVFXK73UpOTo74TmpqqioqKiRJFRUVESFdv7x+2dfVBAIBHT58+IS95eXlKSkpyZnS09NPd3VPikvS+OffJ6wBoI2wOqjHjBmjH/7whxo0aJCysrK0dOlSVVdX67XXXot2a8rNzZXf73em3bt3n7Xfdkk89xsA2girg/p4ycnJuuiii/TJJ58oLS1NoVBI1dXVETWVlZXOOe20tLQGV4HXf/6mGq/Xq/bt25+wF4/HI6/XGzGdTdxXDQBtQ4sK6oMHD+rTTz9Vly5dNGzYMMXHx6uwsNBZXl5erl27dsnn80mSfD6ftmzZor179zo1BQUF8nq96tevn1Nz7Bj1NfVjAAAQTVYH9U9/+lMVFRVp586dWrt2ra6//nrFxsZq3LhxSkpK0qRJkzRjxgytXLlSJSUlmjhxonw+ny6//HJJ0qhRo9SvXz/ddttt2rRpk5YvX65f/OIXysnJkcfjkSRNnTpVn332mWbNmqWPP/5Yzz33nF577TXdd9990Vz1b1RXW6MDBw7o4MGDnKsGgFbM6qD++9//rnHjxqlPnz760Y9+pPPOO0/r1q1T586dJUlPPfWUvv/97+vGG2/UiBEjlJaWpj/+8Y/O92NjY/XWW28pNjZWPp9Pt956q26//XY9+uijTk3Pnj319ttvq6CgQIMHD9a8efP04osvWndrlnQ0nI8NZd5RDQCtn8uwO9YsAoGAkpKS5Pf7T+t8dSgU0g+fXq7a4BG5YuMi7peuq61RrKe9YmJiJUnP33qJ7l5UpkV3j5Db7T7tdQAA2MfqPWp8M95RDQCtG0ENAIDFCOoW5uh56n+9l/rYx4oCAFofgrqF47GiANC6EdQt0PF71S5Jt8xfqUOHDkWvKQDAGUFQt1D1h7zr8aQyAGidCOoWyoRrddfvNkTsWQeDQR6AAgCtDEHdgh2/F80DUACg9SGoWxkOgQNA60JQt3DHP1YUANC6ENStDE8qA4DWhaBuZXgACgC0LgR1K3DsfdU8AAUAWheCuhVySVz9DQCtBEHdSvAAFABonQjqVuL4B6BwrhoAWgeCuhU5di/ahGs5/A0ArQBB3cpE3Fd93OFwAEDLQ1ADAGAxgrqVC4VC7FUDQAtGULdCEfdVc1EZALRoBHUrxxu1AKBlI6hbqWP3qrmnGgBaLoIaAACLEdRtQLgmpIMHD3KeGgBaIIK6FXMuJAvXauJL6zhPDQAtEEHdih37WFHOUwNAy0RQt3L1Ac1tWgDQMhHUbUBdbY3qamt0y/yVOnToULTbAQCcAoK6DeHwNwC0PPyXu40JBoOSpHPOOUculyvK3QAAvgl71G0MTyoDgJaFoG4jeFIZALRMBHUbcuyV31wBDgAtA0HdhtTfV11XG+IKcABoIQjqNqb+sLcrJpa9agBoAQjqNorHigJAy0BQt0H1F5axVw0A9iOo2zATruVcNQBYjqBuo47uVRvFxMZxFTgAWIygbsPqD4EfOnRIP/xVoQ4dOkRYA4BlCOo2rn5v2iXxxDIAsBBB3cYd+85qU1engwcPslcNABYhqKGY2Lh/vgozxC1bAGAZHvqMSMY4b9iKj4/nDVsAEGXsUcNRfyU4F5cBgD0IakQ49uKy8c+/T1gDQJQR1IgQcXFZbY1uWVBEWANAFBHUaKD+4jJj6rhtCwCijKDGCdXV1ihcE1JduFb79u1TIBBQMBhk7xoAziKu+sY3MuFa3fHbPysmLl6SSy9PuVIdOnTginAAOAvYo8ZJiYmNU0xsnFySbv/NalVVVenIkSPsYQPAGcYeNU5aXe3R89QuSbcvWKmYuHi5XDH6/d3fkcfj4b5rADgD2KPGKTn2rVsxsXFyxcRq//79+v+eWq6qqiodOHCAvWwAaEYE9XHmz5+vHj16qF27dsrIyNCGDRui3ZK16h87eudLf5aRdOjQIY37VYFufPId59A4h8cB4PRw6PsYr776qmbMmKHnn39eGRkZevrpp5WVlaXy8nKlpKREuz1rxcTGOfdfx8Qe/St167PvyhUTp1i3W5JL+ZOv0DnnnBPxPZfLJbfbzeFyAPgaLsOujiMjI0OXXXaZfv3rX0uS6urqlJ6ernvuuUcPPPDA1343EAgoKSlJfr9fXq+3yT2EQiH98Onlqg0ekSs2LiLE6mprvnHeydREZaxw7dF5/wxvEw4rxu3R76eOUHx8/Am3h8vlUnx8vGprazkHDqBNYo/6n0KhkEpKSpSbm+vMi4mJUWZmpoqLi6PYWesQExsnGSNX/f/GxCh85Cvd9NQyuWKOC/hjwlwxMXpx4uWa+odS/c/kK7421JtT/d6+dPTvhiT2/gFEBUH9T19++aXC4bBSU1Mj5qempurjjz9uUB8MBp23TEmS3++XdHTP+nSEQiEFDwUUDh2RXHERIWbCNd8472RqojHWqY5fGzrszBv/5JuKifPohv96zZlXFw7LFROrY3Pz+HknU3P8PFdsvEw4LFdsrOZP8EmSpv1uvWLi4vXbyVc533G73REBDqDtaM7/z5977rnfuANAUDdRXl6eHnnkkQbz09PTo9ANzoSL/jPy8/kPR6UNAK3YyZwuJaj/qVOnToqNjVVlZWXE/MrKSqWlpTWoz83N1YwZM5zPdXV1qqqq0nnnndfkw6OBQEDp6enavXv3aZ3nbqvYfqeH7Xd62H6np61uv3PPPfcbawjqf3K73Ro2bJgKCws1duxYSUfDt7CwUNOmTWtQ7/F45PF4IuYlJyc3Sy9er7dN/UVtbmy/08P2Oz1sv9PD9muIoD7GjBkzNGHCBF166aUaPny4nn76aR06dEgTJ06MdmsAgDaKoD7GTTfdpH/84x+aM2eOKioqNGTIEC1btqzBBWYAAJwtBPVxpk2b1uih7rPB4/HooYceanBIHSeH7Xd62H6nh+13eth+J8YDTwAAsBjP+gYAwGIENQAAFiOoAQCwGEFtCV6vedTq1at17bXXqmvXrnK5XHr99dcjlhtjNGfOHHXp0kXt27dXZmam/vrXv0bUVFVVafz48fJ6vUpOTtakSZN08ODBiJrNmzfrqquuUrt27ZSenq65c+ee6VU74/Ly8nTZZZfp3HPPVUpKisaOHavy8vKImiNHjignJ0fnnXeeEhMTdeONNzZ4yM+uXbuUnZ2thIQEpaSkaObMmaqtrY2oWbVqlYYOHSqPx6PevXsrPz//TK/eGbdgwQINGjTIuY/X5/PpnXfecZaz7U7NY489JpfLpenTpzvz2IZNZBB1ixYtMm6327z00ktm69atZvLkySY5OdlUVlZGu7WzbunSpebnP/+5+eMf/2gkmSVLlkQsf+yxx0xSUpJ5/fXXzaZNm8x1111nevbsaQ4fPuzUjB492gwePNisW7fOvP/++6Z3795m3LhxznK/329SU1PN+PHjTVlZmXnllVdM+/btzW9+85uztZpnRFZWllm4cKEpKyszpaWl5nvf+57p1q2bOXjwoFMzdepUk56ebgoLC83GjRvN5Zdfbr797W87y2tra82AAQNMZmam+eijj8zSpUtNp06dTG5urlPz2WefmYSEBDNjxgyzbds28+yzz5rY2FizbNmys7q+ze3NN980b7/9tvnLX/5iysvLzc9+9jMTHx9vysrKjDFsu1OxYcMG06NHDzNo0CBz7733OvPZhk1DUFtg+PDhJicnx/kcDodN165dTV5eXhS7ir7jg7qurs6kpaWZJ554wplXXV1tPB6PeeWVV4wxxmzbts1IMh988IFT88477xiXy2U+//xzY4wxzz33nOnQoYMJBoNOzezZs02fPn3O8BqdXXv37jWSTFFRkTHm6LaKj483ixcvdmq2b99uJJni4mJjzNF/KMXExJiKigqnZsGCBcbr9Trba9asWaZ///4Rv3XTTTeZrKysM71KZ12HDh3Miy++yLY7BQcOHDDf+ta3TEFBgbn66qudoGYbNh2HvqOs/vWamZmZzjxer9m4HTt2qKKiImJbJSUlKSMjw9lWxcXFSk5O1qWXXurUZGZmKiYmRuvXr3dqRowYEfEGnKysLJWXl2v//v1naW3OvPo3unXs2FGSVFJSopqamojt17dvX3Xr1i1i+w0cODDiIT9ZWVkKBALaunWrU3PsGPU1renvazgc1qJFi3To0CH5fD623SnIyclRdnZ2g/VkGzYdDzyJslN9vWZbVlFRIUmNbqv6ZRUVFUpJSYlYHhcXp44dO0bU9OzZs8EY9cs6dOhwRvo/m+rq6jR9+nRdccUVGjBggKSj6+Z2uxs8k/747dfY9q1f9nU1gUBAhw8fVvv27c/EKp0VW7Zskc/n05EjR5SYmKglS5aoX79+Ki0tZdudhEWLFunDDz/UBx980GAZf/+ajqAGWqGcnByVlZVpzZo10W6lRenTp49KS0vl9/v1v//7v5owYYKKioqi3VaLsHv3bt17770qKChQu3btot1Oq8Kh7yg71ddrtmX12+PrtlVaWpr27t0bsby2tlZVVVURNY2NcexvtGTTpk3TW2+9pZUrV+qCCy5w5qelpSkUCqm6ujqi/vjt903b5kQ1Xq+3xe/NuN1u9e7dW8OGDVNeXp4GDx6sZ555hm13EkpKSrR3714NHTpUcXFxiouLU1FRkX71q18pLi5OqampbMMmIqij7NjXa9arf72mz+eLYmf26dmzp9LS0iK2VSAQ0Pr1651t5fP5VF1drZKSEqdmxYoVqqurU0ZGhlOzevVq1dTUODUFBQXq06dPiz7sbYzRtGnTtGTJEq1YsaLB4f1hw4YpPj4+YvuVl5dr165dEdtvy5YtEf/YKSgokNfrVb9+/ZyaY8eor2mNf1/r6uoUDAbZdidh5MiR2rJli0pLS53p0ksv1fjx450/sw2bKNpXs+Ho7Vkej8fk5+ebbdu2mSlTppjk5OSIKx/bigMHDpiPPvrIfPTRR0aSefLJJ81HH31k/va3vxljjt6elZycbN544w2zefNm84Mf/KDR27MuueQSs379erNmzRrzrW99K+L2rOrqapOammpuu+02U1ZWZhYtWmQSEhJa/O1Zd911l0lKSjKrVq0ye/bscaavvvrKqZk6darp1q2bWbFihdm4caPx+XzG5/M5y+tvjxk1apQpLS01y5YtM507d2709piZM2ea7du3m/nz57eK22MeeOABU1RUZHbs2GE2b95sHnjgAeNyucy7775rjGHbNcWxV30bwzZsKoLaEs8++6zp1q2bcbvdZvjw4WbdunXRbikqVq5caSQ1mCZMmGCMOXqL1oMPPmhSU1ONx+MxI0eONOXl5RFj7Nu3z4wbN84kJiYar9drJk6caA4cOBBRs2nTJnPllVcaj8djzj//fPPYY4+drVU8YxrbbpLMwoULnZrDhw+bu+++23To0MEkJCSY66+/3uzZsydinJ07d5oxY8aY9u3bm06dOpn777/f1NTURNSsXLnSDBkyxLjdbtOrV6+I32ipfvKTn5ju3bsbt9ttOnfubEaOHOmEtDFsu6Y4PqjZhk3D27MAALAY56gBALAYQQ0AgMUIagAALEZQAwBgMYIaAACLEdQAAFiMoAYAwGIENQAAFiOoAQCwGEEN4JR85zvf0fTp060fE2gtCGoAACxGUAM4aT/+8Y9VVFSkZ555Ri6XSy6XSzt37lRZWZnGjBmjxMREpaam6rbbbtOXX34pSVq1apXcbrfef/99Z5y5c+cqJSVFlZWVJxwTwFG8lAPASfP7/RozZowGDBigRx99VJIUHx+viy++WHfccYduv/12HT58WLNnz1Ztba1WrFghSZo1a5Zee+01bdq0SZ999pkuv/xyLV68WNddd12jY3bu3FmxsbFRW0/AJnHRbgBAy5GUlCS3262EhASlpaVJkn75y1/qkksu0X/91385dS+99JLS09P1l7/8RRdddJF++ctfqqCgQFOmTFFZWZkmTJig66677oRjAvgXghrAadm0aZNWrlypxMTEBss+/fRTXXTRRXK73fr973+vQYMGqXv37nrqqaei0CnQMhHUAE7LwYMHde211+rxxx9vsKxLly7On9euXStJqqqqUlVVlc4555yz1iPQkhHUAE6J2+1WOBx2Pg8dOlT/93//px49eigurvH/pHz66ae677779N///d969dVXNWHCBL333nuKiYlpdEwA/8JV3wBOSY8ePbR+/Xrt3LlTX375pXJyclRVVaVx48bpgw8+0Keffqrly5dr4sSJCofDCofDuvXWW5WVlaWJEydq4cKF2rx5s+bNm3fCMevq6qK4hoBdCGoAp+SnP/2pYmNj1a9fP3Xu3FmhUEh//vOfFQ6HNWrUKA0cOFDTp09XcnKyYmJi9J//+Z/629/+pt/85jeSjh4Of+GFF/SLX/xCmzZtanTMXbt2RXMVAatwexYAABZjjxoAAIsR1AAAWIygBgDAYgQ1AAAWI6gBALAYQQ0AgMUIagAALEZQAwBgMYIaAACLEdQAAFiMoAYAwGIENQAAFvt/sNVduMZ2kRYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wc = df['text'].str.split().str.len()\n",
    "sns.displot(wc)\n",
    "max(wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5915\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Figuring out the max length of sequences to set limit for tokenizer\n",
    "import seaborn as sns\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "token_lens = []\n",
    "for txt in list(df.text):\n",
    "    tokens = tokenizer.encode(txt, \n",
    "                            #   max_length=512, \n",
    "                            truncation=False)\n",
    "    token_lens.append(len(tokens))\n",
    "sns.displot(token_lens)\n",
    "print(max(token_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at /Users/michaelrosen/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/vocab.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /Users/michaelrosen/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer_config.json\n",
      "loading file tokenizer.json from cache at /Users/michaelrosen/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer.json\n",
      "loading configuration file config.json from cache at /Users/michaelrosen/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Map (num_proc=24): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375678/375678 [01:10<00:00, 5323.98 examples/s] \n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_function(reports):\n",
    "    return tokenizer(reports[\"text\"], return_tensors=\"np\", truncation=True, padding=\"max_length\")\n",
    "\n",
    "tokenized_ds = dataset.map(tokenize_function, batched=True, num_proc=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/michaelrosen/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.45.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /Users/michaelrosen/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/model.safetensors\n",
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Generate config GenerationConfig {\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "A pretrained model of type `BertForMaskedLM` contains parameters that have been renamed internally (a few are listed below but more are present in the model):\n",
      "* `bert.embeddings.LayerNorm.gamma` -> `bert.embeddings.LayerNorm.weight`\n",
      "* `bert.encoder.layer.0.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.0.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.1.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.1.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.10.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.10.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.11.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.11.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.2.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.2.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.3.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.3.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.4.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.4.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.5.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.5.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.6.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.6.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.7.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.7.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.8.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.8.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.9.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.9.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `cls.predictions.transform.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.embeddings.LayerNorm.beta` -> `bert.embeddings.LayerNorm.bias`\n",
      "* `bert.encoder.layer.0.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.0.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.1.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.1.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.10.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.10.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.11.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.11.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.2.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.2.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.3.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.3.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.4.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.4.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.5.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.5.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.6.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.6.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.7.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.7.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.8.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.8.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.9.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.9.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `cls.predictions.transform.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "If you are using a model from the Hub, consider submitting a PR to adjust these weights and help future users.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertForMaskedLM were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n",
      "Generation config file not found, using a generation config created from the model config.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "# Model configuration\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')#,\n",
    "                                        # torch_dtype=torch.float16, attn_implementation=\"sdpa\", # these are for efficiency\n",
    "                                        # num_labels=2 # https://github.com/huggingface/transformers/issues/27707\n",
    "                                        # )\n",
    "# model = BertForMaskedLM.from_pretrained('./event_trainer/checkpoint-43500') \n",
    "\n",
    "# Evaluation \n",
    "metric = evaluate.load(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    labels = eval_pred.label_ids\n",
    "    preds = eval_pred.predictions.argmax(axis = -1)\n",
    "    for i in range(0,len(labels)):\n",
    "        metric.add_batch(predictions=preds[i], references=labels[i])\n",
    "    # return metric.compute(predictions=preds, references=labels)\n",
    "    return metric.compute()\n",
    "\n",
    "# Data\n",
    "train_eval_ds = tokenized_ds.train_test_split(test_size=0.1, shuffle=True,seed=42)\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)\n",
    "\n",
    "# Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"event_trainer4\", \n",
    "    eval_strategy=\"epoch\",\n",
    "    eval_accumulation_steps = 32, # avoid OOM error, but putting preditictions during evalauation on the CPU\n",
    "    per_device_eval_batch_size = 1, # This fixes the array size > 2**32 error if more than one batch is left on GPU\n",
    "    num_train_epochs = 5,#, # default is 3,\n",
    "    do_eval = True\n",
    "    )\n",
    "\n",
    "small_eval_dataset = train_eval_ds['test'].select(list(range(0,5000)))\n",
    "# small_train_dataset = train_eval_ds[\"train\"].select(list(range(0,1000)))\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_eval_ds[\"train\"],\n",
    "    # train_dataset=small_train_dataset,\n",
    "    eval_dataset = small_eval_dataset,\n",
    "    # eval_dataset = train_eval_ds[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from event_trainer4/checkpoint-42000.\n",
      "There were missing keys in the checkpoint model loaded: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias'].\n",
      "The following columns in the training set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: eid, text, __index_level_0__. If eid, text, __index_level_0__ are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/trainer.py:3262: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
      "***** Running training *****\n",
      "  Num examples = 338,110\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 211,320\n",
      "  Number of trainable parameters = 109,514,298\n",
      "  Continuing training from checkpoint, will skip to saved global_step\n",
      "  Continuing training from epoch 0\n",
      "  Continuing training from global step 42000\n",
      "  Will skip the first 0 epochs then the first 42000 batches in the first epoch.\n",
      "  0%|          | 0/211320 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/trainer.py:2944: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_rng_state = torch.load(rng_file)\n",
      " 20%|â–ˆâ–‰        | 42237/211320 [01:14<44:05, 63.91it/s]   The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: eid, text, __index_level_0__. If eid, text, __index_level_0__ are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 8\n",
      " 20%|â–ˆâ–ˆ        | 42264/211320 [01:30<44:05, 63.91it/s]"
     ]
    }
   ],
   "source": [
    "trainer.train(resume_from_checkpoint = True)\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(trainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mlog_history)\n\u001b[1;32m      2\u001b[0m x\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "x = pd.DataFrame(trainer.state.log_history)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.state.best_model_checkpoint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
